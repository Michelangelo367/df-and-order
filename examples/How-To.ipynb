{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df-and-order how-to!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is df-and-order anyway?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `df-and-order` all your interactions with dataframes become very clean and predictable.\n",
    "\n",
    "Say you've been working on some project for one month already and you had a bunch of experiments. Now your working directory ended up like this:\n",
    "\n",
    "    data/\n",
    "    ├── raw_df_proj1.csv\n",
    "    ├── raw_df_new_prj1.csv\n",
    "    ├── cleaned_df_v1.csv\n",
    "    ├── cleaned_df_the_best.csv\n",
    "    ├── cleaned_df.csv\n",
    "    └── cleaned_df_improved.csv\n",
    "Looks familiar? :) Except the namings it would be challenging to find how exactly those files were generated. How to reproduce the result? It's feasible to find the roots ( at least if you use git ) yet it's very time-consuming.\n",
    "\n",
    "`df-and-order` was made to tackle these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It always starts with some intial, commonly raw dataframe. It could be some logs, backend table etc. Then we come to play with it, transform it somehow to get a nice final dataframe. \n",
    "\n",
    "`df-and-order` assigns a config file to every raw dataframe. The config will contain all the useful metadata and more importantly: declaration of every transform possible. Just by looking at the config file we are able to say how some transformation was performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df-and-order` assumes that you already have a dataframe to work with. \n",
    "\n",
    "The only thing the lib wants you to do is to organize your dataframes in separate folders. The lib is config-based so it's nice to have a folder that contains all at once:\n",
    "\n",
    "- the initial dataframe \n",
    "\n",
    "- a config for it \n",
    "\n",
    "- all transformed variations of the initial dataframe.\n",
    "\n",
    "You should pick a unique identifier for each dataframe, it will serve as the folder name and the filename for the initial dataframe.\n",
    "\n",
    "Example of such structure:\n",
    "\n",
    "    data/\n",
    "    ├── unique_df_id_1/ - folder with all artifacts for df with id unique_df_id_1\n",
    "    │   ├── unique_df_id_1.csv - initial dataframe\n",
    "    │   ├── df_config.yaml - contains metadata and declared transformations\n",
    "    │   ├── transform_1_unique_df_id_1.csv - first transformed df\n",
    "    │   └── transform_2_unique_df_id_1.csv - second transformed df\n",
    "    ├── unique_df_id_2/ - same goes with other dataframes\n",
    "    │   ├── ...\n",
    "    │   └── ...\n",
    "    └── unique_df_id_3/\n",
    "        ├── ...\n",
    "        ├── ...\n",
    "        ├── ...\n",
    "        └── ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. We need a dataframe!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a dataframe so we are going to create it by hand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df = pd.DataFrame({\n",
    "    'num_col': [1,2,3,4,5],\n",
    "    'str_col': ['one', 'two', 'three', 'four', 'five'],\n",
    "    'date_col': ['2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21'],\n",
    "    'redundant_col': [0, 0, 0, 0, 0]\n",
    "})\n",
    "example_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose an id for our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df_id = 'super_demo_df_2020'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a folder for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "df_folder_path = os.path.join('data', example_df_id)\n",
    "if not os.path.exists(df_folder_path):\n",
    "    os.makedirs(df_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only thing left is to save our dataframe there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = example_df_id + '.csv'\n",
    "example_df.to_csv(os.path.join(df_folder_path, filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hooray! Next step is to create a config file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Config file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Config file contains all metadata we are interested in and all transformations needed as well.\n",
    "\n",
    "`DfReader` operates in your data folder and knows where to locate all dataframes and configs for them. We will create new config using `DfReader` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from df_and_order.df_reader import DfReader\n",
    "from df_and_order.df_cache import DfCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DfReader is able to work with any format you want by using `DfCache` subclasses. Each subclass provides logic how to save/load a dataframe. \n",
    "\n",
    "See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDfCache(DfCache):\n",
    "    # just a basic wrapper around pandas csv built-in methods.\n",
    "    def _save(self, df: pd.DataFrame, path: str, *args, **kwargs):\n",
    "        df.to_csv(path, index=False, *args, **kwargs)\n",
    "\n",
    "    def _load(self, path: str, *args, **kwargs) -> pd.DataFrame:\n",
    "        return pd.read_csv(path, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use it for our needs.\n",
    "\n",
    "Just as I mentioned earlier, we first need an instance of `DfReader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we must declare with which format we want to operate\n",
    "df_format = 'csv'\n",
    "# empty string means we want to store dataframes in the current directory.\n",
    "# can be any path you want.\n",
    "dir_path = 'data/'\n",
    "reader = DfReader(dir_path=dir_path, format_to_cache_map={\n",
    "    # DfReader now knows how to work with csv files.\n",
    "    df_format: CsvDfCache()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are all set for now and ready to create a config!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may want to provide any additional information for describing a dataset\n",
    "# here, as an example, we save the info about the dataset's author\n",
    "metadata = {'author': 'Data Man'}\n",
    "# the unique id we came up with above. \n",
    "df_id = example_df_id\n",
    "# other information is already available for us\n",
    "reader.create_df_config(df_id=df_id, # config will store dataframe id as well\n",
    "                        initial_df_format=df_format, # in which format initial dataframe is saved\n",
    "                        transformed_df_format=df_format, # in which format to save a transformed datafarme\n",
    "                        metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transformed_df_format: csv\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/super_demo_df_2020/df_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple as that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader.read(df_id=df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started with the code just right away because how simple it is and how intuitive it is!\n",
    "\n",
    "You just need to provide a dataframe id and you are ready to go. No more hardcoded paths and mixed up formats. Once you set up `DfReader` - all just works behind the scenes. \n",
    "\n",
    "Just imagine how beneficial it is when working in the same repository with many fellow colleagues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Still not convinced df-and-order is useful? Just watch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to hide all the logic behind your own subclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmazingDfReader(DfReader):\n",
    "    def __init__(self):\n",
    "        # while working in some repo, our data is usually stored in some specific\n",
    "        # place we can provide a path for\n",
    "        dir_path = 'data'\n",
    "        reader = super().__init__(dir_path=dir_path, format_to_cache_map={\n",
    "            # here we list all the formats we want to work with\n",
    "            'csv': CsvDfCache()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader = AmazingDfReader()\n",
    "amazing_reader.read(df_id=df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you see how cool it is? Anybody can use AmazingDfReader across the codebase in a super clean way without bothering how it's configured!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very often our initial dataframe is the raw one and needs to be transformed in some way. \n",
    "\n",
    "e.g. we want to have the initial dataframe containing some important information yet we don't need all of it to fit our model. \n",
    "\n",
    "`df-and-order` supports `in-memory` transformations as well as `permanent` ones. The only difference is that in the permanent case we store the resulting dataframe on disk next to the initial df. \n",
    "\n",
    "You can see a transformation as a combination of one or many steps.\n",
    "\n",
    "e.g.\n",
    "\n",
    "    - first drop column 'redundant_col'\n",
    "    - then convert column 'date_col' from str to date\n",
    "    Do it all in memory only\n",
    "\n",
    "Each step represents a class with the only method `transform` that takes a df and returns a df.\n",
    "\n",
    "    class DropColsTransformStep(DfTransformStep):\n",
    "        \"\"\"\n",
    "        Simply drops some undesired columns from a dataframe.\n",
    "        \"\"\"\n",
    "        def __init__(self, cols: List[str]):\n",
    "            self._cols_to_drop = cols\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        return df.drop(self._cols_to_drop, axis=1)\n",
    "\n",
    "Then we are able to declare it as a transform step:\n",
    "\n",
    "The easiest way is to just pass `DfTransformStep` suclass type:\n",
    "\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                         params={'cols': ['redundant_col']}),\n",
    "                                         \n",
    "Important note here:\n",
    "\n",
    "`DfTransformStep` suclass should be stored in the separate file, not in some notebook etc. \n",
    "\n",
    "Otherwise, `df-and-order` will not be able to locate it.\n",
    "                                         \n",
    "Another way is to provide the full module path for your `DfTransformStep` suclass, including the class name. Choose whatever suits you.\n",
    "\n",
    "    DfTransformStepConfig(module_path='df_and_order.steps.DropColsTransformStep',\n",
    "                          params={'cols': ['redundant_col']}),\n",
    "\n",
    "In both cases `params` will be passed to init method of the specified `DfTransformStep` suclass.\n",
    "\n",
    "All the transforms declarations will be translated to the config file. \n",
    "\n",
    "Let's see how it works in the next example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to remove `redundant_col` since it doesn't provide any useful information and we also need to convert `date_col` to datetime. Since our dataframe is quite small, we will do all the transformations in memory, without any intermediates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from df_and_order.df_transform import DfTransformConfig\n",
    "from df_and_order.df_transform_step import DfTransformStepConfig\n",
    "from df_and_order.steps import DropColsTransformStep, DatesTransformStep\n",
    "\n",
    "# we describe all the steps required\n",
    "in_memory_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                         params={'cols': ['redundant_col']}),\n",
    "    DfTransformStepConfig.from_step_type(step_type=DatesTransformStep,\n",
    "                                         params={'cols': ['date_col']})\n",
    "]\n",
    "\n",
    "# arbitrary unique id for our transformation\n",
    "example_transform_id = 'model_input'\n",
    "# here's the instance of our entire transform\n",
    "example_transform = DfTransformConfig(transform_id=example_transform_id, \n",
    "                                      in_memory_steps=in_memory_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_df = amazing_reader.read(df_id=df_id, \n",
    "                                     transform=example_transform)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   num_col   5 non-null      int64         \n",
      " 1   str_col   5 non-null      object        \n",
      " 2   date_col  5 non-null      datetime64[ns]\n",
      "dtypes: datetime64[ns](1), int64(1), object(1)\n",
      "memory usage: 248.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "transformed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretty rad, isn't it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our transform is now visible in the config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transformed_df_format: csv\r\n",
      "transforms:\r\n",
      "  model_input:\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n",
      "    - module_path: df_and_order.steps.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/super_demo_df_2020/df_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: you are free to edit the config file manually as well!\n",
    "\n",
    "Once a transform is declared in the config file you can just pass `transform_id` to the `DfReader.read` method. See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=example_transform_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe you want to switch to your initial dataframe? No problem! Just don't pass `transform_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_df = amazing_reader.read(df_id=df_id)\n",
    "initial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5 entries, 0 to 4\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   num_col        5 non-null      int64 \n",
      " 1   str_col        5 non-null      object\n",
      " 2   date_col       5 non-null      object\n",
      " 3   redundant_col  5 non-null      int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 288.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "initial_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's cover the case when we want to persist a transform's result. It's a good idea to remove `redundant_col` once and for all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we describe all the steps required\n",
    "in_memory_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DatesTransformStep,\n",
    "                                         params={'cols': ['date_col']})\n",
    "]\n",
    "\n",
    "# let's just move DropColsTransformStep from in_memory to permanent steps\n",
    "permanent_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DropColsTransformStep,\n",
    "                                     params={'cols': ['redundant_col']}),\n",
    "]\n",
    "\n",
    "# arbitrary unique id for our transformation\n",
    "permanent_transform_id = 'model_input_permanent'\n",
    "# here's the instance of our entire transform\n",
    "permanent_transform = DfTransformConfig(transform_id=permanent_transform_id, \n",
    "                                        in_memory_steps=in_memory_steps,\n",
    "                                        permanent_steps=permanent_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = amazing_reader.read(df_id=df_id, \n",
    "                               transform=permanent_transform)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transformed_df_format: csv\r\n",
      "transforms:\r\n",
      "  model_input:\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n",
      "    - module_path: df_and_order.steps.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "  model_input_permanent:\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "    permanent:\r\n",
      "    - module_path: df_and_order.steps.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/super_demo_df_2020/df_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 24\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  634 May 18 11:52 df_config.yaml\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  114 May 18 11:52 model_input_permanent_super_demo_df_2020.csv\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 May 18 11:52 super_demo_df_2020.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/super_demo_df_2020/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we now see `model_input_permanent_example_df_2020.csv` file stored to the disk.\n",
    "\n",
    "Every time we read it - it recovers from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col   date_col\n",
       "0        1     one 2020-05-17\n",
       "1        2     two 2020-05-18\n",
       "2        3   three 2020-05-19\n",
       "3        4    four 2020-05-20\n",
       "4        5    five 2020-05-21"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, \n",
    "                    transform=permanent_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: `in memory` transforms run everytime when your read a dataframe, no matter it was it stored on the disk or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some advanced stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, even after having all the transformation steps declared in the config file, it doesn't prevent us from code changes in those steps subclasses. Once a step is changed, we have an outdated transformed dataframe on the disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df-and-order` has a built-in safety mechanism for avoiding such cases.\n",
    "\n",
    "It compares the creation date of the persisted dataframe with the last modification date of any of the permanent steps. Meaning if a permanent step we used to transform the dataframe was changed afterwards - we can no longer use it. It's crucial while working in the same repo with others. All your team members must read the same dataframe using the same config."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from example_steps.steps import DummyTransformStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from df_and_order.df_transform_step import DfTransformStep\r\n",
      "\r\n",
      "class DummyTransformStep(DfTransformStep):\r\n",
      "    def transform(self, df):\r\n",
      "        return df\r\n"
     ]
    }
   ],
   "source": [
    "!cat example_steps/steps.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transform above does literally nothing, but bear with me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "permanent_steps = [\n",
    "    DfTransformStepConfig.from_step_type(step_type=DummyTransformStep, params={})\n",
    "]\n",
    "dummy_transform_id = 'dummy'\n",
    "dummy_transform = DfTransformConfig(transform_id=dummy_transform_id, \n",
    "                                    permanent_steps=permanent_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, \n",
    "                    transform=dummy_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_id: super_demo_df_2020\r\n",
      "initial_df_format: csv\r\n",
      "metadata:\r\n",
      "  author: Data Man\r\n",
      "transformed_df_format: csv\r\n",
      "transforms:\r\n",
      "  dummy:\r\n",
      "    permanent:\r\n",
      "    - module_path: example_steps.steps.DummyTransformStep\r\n",
      "  model_input:\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n",
      "    - module_path: df_and_order.steps.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "  model_input_permanent:\r\n",
      "    in_memory:\r\n",
      "    - module_path: df_and_order.steps.DatesTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - date_col\r\n",
      "    permanent:\r\n",
      "    - module_path: df_and_order.steps.DropColsTransformStep\r\n",
      "      params:\r\n",
      "        cols:\r\n",
      "        - redundant_col\r\n"
     ]
    }
   ],
   "source": [
    "!cat data/super_demo_df_2020/df_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 32\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  716 May 18 11:52 df_config.yaml\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 May 18 11:52 dummy_super_demo_df_2020.csv\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  114 May 18 11:52 model_input_permanent_super_demo_df_2020.csv\r\n",
      "-rw-r--r--  1 ilya.tyutin  staff  138 May 18 11:52 super_demo_df_2020.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/super_demo_df_2020/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing new so far. But now let's change the transform step file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('example_steps/steps.py', \"a\") as file:\n",
    "    file.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we then try to read the transformed dataframe - it crashes since the code of our dummy step was modified after the dataframe was persisted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "['example_steps.steps.DummyTransformStep'] steps were changed since the df was generated, delete the file and try again to regenerate the df.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-120d5f230a47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mamazing_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdummy_transform_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/df_and_order/df_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, df_id, transform_id, transform)\u001b[0m\n\u001b[1;32m    139\u001b[0m             return self._read_transformed(df_id=df_id,\n\u001b[1;32m    140\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                                           df_config=df_config)\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             return self._read_initial(df_id=df_id,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/df_and_order/df_reader.py\u001b[0m in \u001b[0;36m_read_transformed\u001b[0;34m(self, df_id, transform, df_config)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdated_steps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                     \u001b[0msteps_module_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_path\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutdated_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                     raise Exception(f'{steps_module_paths} steps were changed since the df was generated, '\n\u001b[0m\u001b[1;32m    186\u001b[0m                                     'delete the file and try again to regenerate the df.')\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: ['example_steps.steps.DummyTransformStep'] steps were changed since the df was generated, delete the file and try again to regenerate the df."
     ]
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=dummy_transform_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be annoying to get such en error after some minor changes, e.g. something was renamed or blank lines were removed.\n",
    "\n",
    "But it's better to get an error rather than outdated wrong dataframe.\n",
    "If we remove the file and try again - everything works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm data/super_demo_df_2020/dummy_super_demo_df_2020.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_col</th>\n",
       "      <th>str_col</th>\n",
       "      <th>date_col</th>\n",
       "      <th>redundant_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>one</td>\n",
       "      <td>2020-05-17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>two</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>three</td>\n",
       "      <td>2020-05-19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>four</td>\n",
       "      <td>2020-05-20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>five</td>\n",
       "      <td>2020-05-21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_col str_col    date_col  redundant_col\n",
       "0        1     one  2020-05-17              0\n",
       "1        2     two  2020-05-18              0\n",
       "2        3   three  2020-05-19              0\n",
       "3        4    four  2020-05-20              0\n",
       "4        5    five  2020-05-21              0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazing_reader.read(df_id=df_id, transform_id=dummy_transform_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
